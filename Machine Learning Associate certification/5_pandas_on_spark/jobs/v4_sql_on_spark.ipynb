{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pyspark.pandas as ps\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf = ps.DataFrame({\n",
    "    \"year\" : [1990,1997,2003,2009,2014],\n",
    "    \"rabbit\" : [20,18,489,675,1776],\n",
    "    \"horse\" : [4,25,281,600,1900]\n",
    "})\n",
    "\n",
    "pdf = pd.DataFrame({\n",
    "    \"year\" : [1990,1997,2003,2009,2014],\n",
    "    \"sheep\" : [22,50,121,445,791],\n",
    "    \"chicken\": [250,326,589,1241,2118]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rabbit</th>\n",
       "      <th>horse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>489</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>675</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>1776</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  rabbit  horse\n",
       "0  1990      20      4\n",
       "1  1997      18     25\n",
       "2  2003     489    281\n",
       "3  2009     675    600\n",
       "4  2014    1776   1900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rabbit</th>\n",
       "      <th>horse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>489</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>675</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>1776</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  rabbit  horse\n",
       "0  2003     489    281\n",
       "1  2009     675    600\n",
       "2  2014    1776   1900"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.sql(\" SELECT * FROM {psdf} WHERE rabbit > 100\", psdf=psdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rabbit</th>\n",
       "      <th>chicken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>675</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1776</td>\n",
       "      <td>2118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rabbit  chicken\n",
       "0      18      326\n",
       "1      20      250\n",
       "2     489      589\n",
       "3     675     1241\n",
       "4    1776     2118"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.sql(\"\"\"\n",
    "SELECT ps.rabbit, pd.chicken\n",
    "       FROM {psdf} ps INNER JOIN {pdf} pd\n",
    "       ON ps.year = pd.year\n",
    "       ORDER BY ps.rabbit, pd.chicken\n",
    "\n",
    "\"\"\",psdf=psdf,pdf=pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas API on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.pandas.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B\n",
       "0  1  10\n",
       "1  2  20\n",
       "2  3  30\n",
       "3  4  40\n",
       "4  5  50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf = ps.DataFrame({\n",
    "    \"A\" : [1,2,3,4,5],\n",
    "    \"B\" : [10,20,30,40,50]\n",
    "})\n",
    "print(type(psdf))\n",
    "psdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+---+---+\n",
      "|  A|  B|\n",
      "+---+---+\n",
      "|  1| 10|\n",
      "|  2| 20|\n",
      "|  3| 30|\n",
      "|  4| 40|\n",
      "|  5| 50|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Converting pandas-on-spark DataFrame to Spark DataFrame\n",
    "sdf = psdf.to_spark()\n",
    "print(type(sdf))\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/pyspark/sql/dataframe.py:5725: FutureWarning: DataFrame.to_pandas_on_spark is deprecated. Use DataFrame.pandas_api instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.pandas.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B\n",
       "0  1  10\n",
       "1  2  20\n",
       "2  3  30\n",
       "3  4  40\n",
       "4  5  50"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf_2 = sdf.to_pandas_on_spark()\n",
    "print(type(psdf_2))\n",
    "psdf_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.pandas.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B\n",
       "0  1  10\n",
       "1  2  20\n",
       "2  3  30\n",
       "3  4  40\n",
       "4  5  50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf_3 = sdf.pandas_api()\n",
    "print(type(psdf_3))\n",
    "psdf_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Spark Execution Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [CASE WHEN isnotnull(__this___index_level_0__#425L) THEN __this___index_level_0__#425L ELSE __that___index_level_0__#433L END AS __index_level_0__#438L, (__this_id#426L + __that_id#434L) AS id#468L]\n",
      "   +- SortMergeJoin [__this___index_level_0__#425L], [__that___index_level_0__#433L], FullOuter\n",
      "      :- Sort [__this___index_level_0__#425L ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(__this___index_level_0__#425L, 200), ENSURE_REQUIREMENTS, [plan_id=419]\n",
      "      :     +- Project [__index_level_0__#402L AS __this___index_level_0__#425L, id#400L AS __this_id#426L]\n",
      "      :        +- Project [distributed_index() AS __index_level_0__#402L, id#400L]\n",
      "      :           +- Range (0, 10, step=1, splits=12)\n",
      "      +- Sort [__that___index_level_0__#433L ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(__that___index_level_0__#433L, 200), ENSURE_REQUIREMENTS, [plan_id=420]\n",
      "            +- Project [__index_level_0__#413L AS __that___index_level_0__#433L, id#411L AS __that_id#434L]\n",
      "               +- Project [distributed_index() AS __index_level_0__#413L, id#411L]\n",
      "                  +- Range (0, 10, step=1, splits=12)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.pandas import option_context\n",
    "\n",
    "with option_context(\n",
    "    \"compute.ops_on_diff_frames\",True,\n",
    "    \"compute.default_index_type\",\"distributed\"\n",
    "):\n",
    "    df = ps.range(10) + ps.range(10)\n",
    "    df.spark.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [__index_level_0__#476L, (id#474L + id#474L) AS id#488L]\n",
      "+- *(1) Project [distributed_index() AS __index_level_0__#476L, id#474L]\n",
      "   +- *(1) Range (0, 10, step=1, splits=12)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with option_context(\n",
    "    \"compute.ops_on_diff_frames\",False,\n",
    "    \"compute.default_index_type\",\"distributed\"\n",
    "):\n",
    "    df = ps.range(10)\n",
    "    df = df + df\n",
    "    df.spark.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Caching DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/01 15:04:39 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- InMemoryTableScan [__index_level_0__#576L, id#588L]\n",
      "      +- InMemoryRelation [__index_level_0__#576L, id#588L, __natural_order__#579L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- *(1) Project [__index_level_0__#496L, (id#494L + id#494L) AS id#508L, __natural_order__#499L]\n",
      "               +- *(1) Project [__index_level_0__#496L, id#494L, monotonically_increasing_id() AS __natural_order__#499L]\n",
      "                  +- *(1) Project [distributed_index() AS __index_level_0__#496L, id#494L]\n",
      "                     +- *(1) Range (0, 10, step=1, splits=12)\n",
      "\n",
      "\n",
      "             id\n",
      "8589934592    0\n",
      "17179869184   2\n",
      "25769803776   4\n",
      "34359738368   6\n",
      "42949672960   8\n",
      "60129542144  10\n",
      "68719476736  12\n",
      "77309411328  14\n",
      "85899345920  16\n",
      "94489280512  18\n"
     ]
    }
   ],
   "source": [
    "with option_context(\n",
    "    \"compute.default_index_type\",\"distributed\"\n",
    "):\n",
    "    df = ps.range(10)\n",
    "    new_df = (df + df ).spark.cache()\n",
    "    new_df.spark.explain()\n",
    "    print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncache the memory\n",
    "new_df.spark.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- InMemoryTableScan [__index_level_0__#576L, id#716L]\n",
      "      +- InMemoryRelation [__index_level_0__#576L, id#716L, __natural_order__#579L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- *(1) Project [__index_level_0__#576L, (id#574L + id#574L) AS id#716L, __natural_order__#579L]\n",
      "               +- *(1) Project [__index_level_0__#576L, id#574L, monotonically_increasing_id() AS __natural_order__#579L]\n",
      "                  +- *(1) Project [distributed_index() AS __index_level_0__#576L, id#574L]\n",
      "                     +- *(1) Range (0, 10, step=1, splits=12)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with (df + df ).spark.cache() as df : \n",
    "    df.spark.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
