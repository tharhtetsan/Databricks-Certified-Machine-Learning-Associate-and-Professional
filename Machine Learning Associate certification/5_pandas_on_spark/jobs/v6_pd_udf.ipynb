{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas series methods\n",
    "def multiply_func(a : pd.Series, b: pd.Series) -> pd.Series:\n",
    "    return a * b\n",
    "\n",
    "x = pd.Series([1,2,3])\n",
    "print(multiply_func(x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.pandas as ps\n",
    "# Create a Spark DataFrame\n",
    "\n",
    "sdf = ps.DataFrame(x, columns=[\"x\"])\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterator of Series UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Iterator\n",
    "from pyspark.sql.functions import col, pandas_udf, struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame([1,2,3], columns=[\"x\"])\n",
    "sdf = ps.DataFrame(pdf)\n",
    "sdf = sdf.to_spark()\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(\"long\")\n",
    "def plus_one(batch_iter : Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    for x in batch_iter:\n",
    "        yield x+1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.select(plus_one(col(\"x\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterator of Multiple Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from typing import Iterator,Tuple\n",
    "\n",
    "@pandas_udf(\"long\")\n",
    "def multiply_two_cols(iterator : Iterator[Tuple[pd.Series,pd.Series]]) -> Iterator[pd.Series]:\n",
    "    for a,b in iterator:\n",
    "        yield a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.select(multiply_two_cols(\"x\",\"x\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series to  scaler UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spdf = ps.DataFrame({\n",
    "    \"id\" : [1,1,1,2,2],\n",
    "    \"v\" : [1.0,2.0,3.0,5.0,10.0]\n",
    "})\n",
    "\n",
    "sdf = spdf.to_spark()\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(\"double\")\n",
    "def mean_udf(v : pd.Series) -> float:\n",
    "    return v.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.select(mean_udf(sdf['v'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.groupby(\"id\").agg(mean_udf(sdf[\"v\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window.partitionBy(\"id\").rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "sdf.withColumn(\"mean_v\", mean_udf(sdf[\"v\"]).over(w)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
